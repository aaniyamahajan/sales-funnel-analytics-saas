{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning & Preparation\n",
    "\n",
    "This notebook handles data loading, cleaning, and preparation for the Sales Funnel Analytics project.\n",
    "\n",
    "## Objectives\n",
    "- Load all CRM datasets\n",
    "- Identify and handle missing values\n",
    "- Fix data type issues\n",
    "- Create cleaned datasets for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all datasets\n",
    "accounts = pd.read_csv('../data/accounts.csv')\n",
    "sales_pipeline = pd.read_csv('../data/sales_pipeline.csv')\n",
    "sales_teams = pd.read_csv('../data/sales_teams.csv')\n",
    "products = pd.read_csv('../data/products.csv')\n",
    "\n",
    "print(f\"Accounts: {accounts.shape[0]} rows, {accounts.shape[1]} columns\")\n",
    "print(f\"Sales Pipeline: {sales_pipeline.shape[0]} rows, {sales_pipeline.shape[1]} columns\")\n",
    "print(f\"Sales Teams: {sales_teams.shape[0]} rows, {sales_teams.shape[1]} columns\")\n",
    "print(f\"Products: {products.shape[0]} rows, {products.shape[1]} columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Explore Data Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== ACCOUNTS ===\")\n",
    "print(accounts.info())\n",
    "print(\"\\n\")\n",
    "accounts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== SALES PIPELINE ===\")\n",
    "print(sales_pipeline.info())\n",
    "print(\"\\n\")\n",
    "sales_pipeline.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== SALES TEAMS ===\")\n",
    "print(sales_teams.info())\n",
    "print(\"\\n\")\n",
    "sales_teams.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== PRODUCTS ===\")\n",
    "print(products.info())\n",
    "print(\"\\n\")\n",
    "products.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Check for Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_missing(df, name):\n",
    "    missing = df.isnull().sum()\n",
    "    missing_pct = (missing / len(df) * 100).round(2)\n",
    "    result = pd.DataFrame({'Missing Count': missing, 'Missing %': missing_pct})\n",
    "    result = result[result['Missing Count'] > 0]\n",
    "    if len(result) > 0:\n",
    "        print(f\"\\n{name} - Missing Values:\")\n",
    "        print(result)\n",
    "    else:\n",
    "        print(f\"\\n{name} - No missing values\")\n",
    "    return result\n",
    "\n",
    "check_missing(accounts, 'Accounts')\n",
    "check_missing(sales_pipeline, 'Sales Pipeline')\n",
    "check_missing(sales_teams, 'Sales Teams')\n",
    "check_missing(products, 'Products')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Clean Sales Pipeline Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check deal stages\n",
    "print(\"Deal Stages:\")\n",
    "print(sales_pipeline['deal_stage'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert date columns to datetime\n",
    "sales_pipeline['engage_date'] = pd.to_datetime(sales_pipeline['engage_date'], errors='coerce')\n",
    "sales_pipeline['close_date'] = pd.to_datetime(sales_pipeline['close_date'], errors='coerce')\n",
    "\n",
    "# Verify conversion\n",
    "print(\"Date column types:\")\n",
    "print(f\"engage_date: {sales_pipeline['engage_date'].dtype}\")\n",
    "print(f\"close_date: {sales_pipeline['close_date'].dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate days to close for closed deals\n",
    "sales_pipeline['days_to_close'] = (sales_pipeline['close_date'] - sales_pipeline['engage_date']).dt.days\n",
    "\n",
    "# Check the calculation\n",
    "closed_deals = sales_pipeline[sales_pipeline['deal_stage'].isin(['Won', 'Lost'])]\n",
    "print(\"Days to close statistics (closed deals):\")\n",
    "print(closed_deals['days_to_close'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create is_won flag for easier analysis\n",
    "sales_pipeline['is_won'] = (sales_pipeline['deal_stage'] == 'Won').astype(int)\n",
    "sales_pipeline['is_closed'] = sales_pipeline['deal_stage'].isin(['Won', 'Lost']).astype(int)\n",
    "\n",
    "print(\"New columns added:\")\n",
    "print(sales_pipeline[['deal_stage', 'is_won', 'is_closed']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Clean Accounts Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check sectors\n",
    "print(\"Sectors:\")\n",
    "print(accounts['sector'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix typo in sector (technolgy -> technology)\n",
    "accounts['sector'] = accounts['sector'].replace('technolgy', 'technology')\n",
    "\n",
    "print(\"Sectors after fix:\")\n",
    "print(accounts['sector'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create company size categories\n",
    "def categorize_size(employees):\n",
    "    if pd.isna(employees):\n",
    "        return 'Unknown'\n",
    "    elif employees < 100:\n",
    "        return 'Small'\n",
    "    elif employees < 500:\n",
    "        return 'Medium'\n",
    "    elif employees < 1000:\n",
    "        return 'Large'\n",
    "    elif employees < 5000:\n",
    "        return 'Enterprise'\n",
    "    else:\n",
    "        return 'Corporate'\n",
    "\n",
    "accounts['company_size'] = accounts['employees'].apply(categorize_size)\n",
    "\n",
    "print(\"Company Size Distribution:\")\n",
    "print(accounts['company_size'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create revenue tier categories\n",
    "def categorize_revenue(revenue):\n",
    "    if pd.isna(revenue):\n",
    "        return 'Unknown'\n",
    "    elif revenue < 100:\n",
    "        return 'Tier 1: < $100M'\n",
    "    elif revenue < 500:\n",
    "        return 'Tier 2: $100M-$499M'\n",
    "    elif revenue < 1000:\n",
    "        return 'Tier 3: $500M-$999M'\n",
    "    elif revenue < 2500:\n",
    "        return 'Tier 4: $1B-$2.5B'\n",
    "    else:\n",
    "        return 'Tier 5: > $2.5B'\n",
    "\n",
    "accounts['revenue_tier'] = accounts['revenue'].apply(categorize_revenue)\n",
    "\n",
    "print(\"Revenue Tier Distribution:\")\n",
    "print(accounts['revenue_tier'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Merge Datasets for Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create master dataset by merging all tables\n",
    "master_df = sales_pipeline.merge(accounts, on='account', how='left')\n",
    "master_df = master_df.merge(sales_teams, on='sales_agent', how='left')\n",
    "master_df = master_df.merge(products, on='product', how='left')\n",
    "\n",
    "print(f\"Master dataset shape: {master_df.shape}\")\n",
    "print(f\"\\nColumns: {master_df.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the merged data\n",
    "master_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for any join issues\n",
    "print(\"Records with missing account info:\", master_df['sector'].isna().sum())\n",
    "print(\"Records with missing sales team info:\", master_df['manager'].isna().sum())\n",
    "print(\"Records with missing product info:\", master_df['series'].isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Save Cleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save cleaned individual datasets\n",
    "accounts.to_csv('../data/accounts_cleaned.csv', index=False)\n",
    "sales_pipeline.to_csv('../data/sales_pipeline_cleaned.csv', index=False)\n",
    "\n",
    "# Save master dataset\n",
    "master_df.to_csv('../data/master_dataset.csv', index=False)\n",
    "\n",
    "print(\"Cleaned datasets saved:\")\n",
    "print(\"- data/accounts_cleaned.csv\")\n",
    "print(\"- data/sales_pipeline_cleaned.csv\")\n",
    "print(\"- data/master_dataset.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Data Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== DATA SUMMARY ===\")\n",
    "print(f\"\\nTotal Opportunities: {len(sales_pipeline):,}\")\n",
    "print(f\"Total Accounts: {len(accounts):,}\")\n",
    "print(f\"Total Sales Agents: {len(sales_teams):,}\")\n",
    "print(f\"Total Products: {len(products):,}\")\n",
    "\n",
    "print(f\"\\n--- Deal Stage Breakdown ---\")\n",
    "for stage, count in sales_pipeline['deal_stage'].value_counts().items():\n",
    "    pct = count / len(sales_pipeline) * 100\n",
    "    print(f\"{stage}: {count:,} ({pct:.1f}%)\")\n",
    "\n",
    "won_deals = sales_pipeline[sales_pipeline['deal_stage'] == 'Won']\n",
    "print(f\"\\n--- Revenue Summary ---\")\n",
    "print(f\"Total Revenue (Won Deals): ${won_deals['close_value'].sum():,.0f}\")\n",
    "print(f\"Average Deal Value: ${won_deals['close_value'].mean():,.0f}\")\n",
    "print(f\"Median Deal Value: ${won_deals['close_value'].median():,.0f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
