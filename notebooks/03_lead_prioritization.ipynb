{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lead Prioritization Model\n",
    "\n",
    "This notebook builds a simple lead prioritization model to help sales teams focus on high-value opportunities.\n",
    "\n",
    "## Objectives\n",
    "1. Identify key factors that predict deal success\n",
    "2. Build a scoring model to prioritize leads\n",
    "3. Apply the model to current pipeline opportunities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the master dataset\n",
    "df = pd.read_csv('../data/master_dataset.csv')\n",
    "df['engage_date'] = pd.to_datetime(df['engage_date'])\n",
    "df['close_date'] = pd.to_datetime(df['close_date'])\n",
    "\n",
    "print(f\"Total records: {len(df):,}\")\n",
    "print(f\"Deal stages: {df['deal_stage'].value_counts().to_dict()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Prepare Training Data\n",
    "\n",
    "We'll use historical closed deals (Won/Lost) to train our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter to closed deals only for training\n",
    "closed_df = df[df['deal_stage'].isin(['Won', 'Lost'])].copy()\n",
    "print(f\"Closed deals for training: {len(closed_df):,}\")\n",
    "print(f\"Win/Loss ratio: {closed_df['is_won'].value_counts().to_dict()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features for the model\n",
    "# We'll use: sector, company_size, revenue_tier, product, regional_office\n",
    "\n",
    "features = ['sector', 'company_size', 'revenue_tier', 'product', 'regional_office', 'series']\n",
    "\n",
    "# Check for missing values\n",
    "print(\"Missing values in features:\")\n",
    "print(closed_df[features].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with missing feature values\n",
    "model_df = closed_df.dropna(subset=features)\n",
    "print(f\"Records after dropping missing: {len(model_df):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical variables\n",
    "encoders = {}\n",
    "X = pd.DataFrame()\n",
    "\n",
    "for feature in features:\n",
    "    le = LabelEncoder()\n",
    "    X[feature] = le.fit_transform(model_df[feature])\n",
    "    encoders[feature] = le\n",
    "\n",
    "y = model_df['is_won'].values\n",
    "\n",
    "print(f\"Feature matrix shape: {X.shape}\")\n",
    "print(f\"Target distribution: Won={y.sum()}, Lost={len(y)-y.sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "print(f\"Training set: {len(X_train):,} samples\")\n",
    "print(f\"Test set: {len(X_test):,} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Random Forest model\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=10,\n",
    "    min_samples_split=20,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "rf_model.fit(X_train, y_train)\n",
    "print(\"Model trained successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "y_pred = rf_model.predict(X_test)\n",
    "y_prob = rf_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"=== MODEL PERFORMANCE ===\")\n",
    "print(f\"\\nROC-AUC Score: {roc_auc_score(y_test, y_prob):.3f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=['Lost', 'Won']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "im = ax.imshow(cm, cmap='Blues')\n",
    "\n",
    "ax.set_xticks([0, 1])\n",
    "ax.set_yticks([0, 1])\n",
    "ax.set_xticklabels(['Lost', 'Won'])\n",
    "ax.set_yticklabels(['Lost', 'Won'])\n",
    "ax.set_xlabel('Predicted')\n",
    "ax.set_ylabel('Actual')\n",
    "ax.set_title('Confusion Matrix', fontsize=14, fontweight='bold')\n",
    "\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        ax.text(j, i, cm[i, j], ha='center', va='center', fontsize=16,\n",
    "                color='white' if cm[i, j] > cm.max()/2 else 'black')\n",
    "\n",
    "plt.colorbar(im)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../visuals/07_confusion_matrix.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Importance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': features,\n",
    "    'importance': rf_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"=== FEATURE IMPORTANCE ===\")\n",
    "print(feature_importance.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize feature importance\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "fi_sorted = feature_importance.sort_values('importance', ascending=True)\n",
    "colors = plt.cm.viridis(np.linspace(0.3, 0.9, len(fi_sorted)))\n",
    "\n",
    "ax.barh(fi_sorted['feature'], fi_sorted['importance'], color=colors)\n",
    "ax.set_xlabel('Importance')\n",
    "ax.set_title('Feature Importance for Lead Prioritization', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../visuals/08_feature_importance.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create Lead Scoring Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_lead(sector, company_size, revenue_tier, product, regional_office, series):\n",
    "    \"\"\"Score a lead based on the trained model.\"\"\"\n",
    "    try:\n",
    "        input_data = pd.DataFrame([{\n",
    "            'sector': encoders['sector'].transform([sector])[0],\n",
    "            'company_size': encoders['company_size'].transform([company_size])[0],\n",
    "            'revenue_tier': encoders['revenue_tier'].transform([revenue_tier])[0],\n",
    "            'product': encoders['product'].transform([product])[0],\n",
    "            'regional_office': encoders['regional_office'].transform([regional_office])[0],\n",
    "            'series': encoders['series'].transform([series])[0]\n",
    "        }])\n",
    "        \n",
    "        probability = rf_model.predict_proba(input_data)[0, 1]\n",
    "        return round(probability * 100, 1)\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "# Test the scoring function\n",
    "test_score = score_lead('technology', 'Enterprise', 'Tier 4: $1B-$2.5B', 'GTXPro', 'Central', 'GTX')\n",
    "print(f\"Test lead score: {test_score}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Score Current Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get current pipeline (Prospecting and Engaging stages)\n",
    "pipeline_df = df[df['deal_stage'].isin(['Prospecting', 'Engaging'])].copy()\n",
    "print(f\"Current pipeline opportunities: {len(pipeline_df):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score each opportunity in the pipeline\n",
    "def score_row(row):\n",
    "    return score_lead(\n",
    "        row['sector'],\n",
    "        row['company_size'],\n",
    "        row['revenue_tier'],\n",
    "        row['product'],\n",
    "        row['regional_office'],\n",
    "        row['series']\n",
    "    )\n",
    "\n",
    "pipeline_df['lead_score'] = pipeline_df.apply(score_row, axis=1)\n",
    "\n",
    "# Check for scoring failures\n",
    "scored_count = pipeline_df['lead_score'].notna().sum()\n",
    "print(f\"Successfully scored: {scored_count:,} / {len(pipeline_df):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create priority tiers\n",
    "def assign_priority(score):\n",
    "    if pd.isna(score):\n",
    "        return 'Unscored'\n",
    "    elif score >= 70:\n",
    "        return 'High Priority'\n",
    "    elif score >= 50:\n",
    "        return 'Medium Priority'\n",
    "    else:\n",
    "        return 'Low Priority'\n",
    "\n",
    "pipeline_df['priority'] = pipeline_df['lead_score'].apply(assign_priority)\n",
    "\n",
    "print(\"=== PIPELINE PRIORITY DISTRIBUTION ===\")\n",
    "print(pipeline_df['priority'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top priority opportunities\n",
    "top_opportunities = pipeline_df[pipeline_df['lead_score'].notna()].nlargest(20, 'lead_score')[\n",
    "    ['opportunity_id', 'account', 'product', 'deal_stage', 'sector', 'company_size', 'sales_agent', 'lead_score', 'priority']\n",
    "]\n",
    "\n",
    "print(\"=== TOP 20 PRIORITY OPPORTUNITIES ===\")\n",
    "print(top_opportunities.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize pipeline by priority\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Priority distribution\n",
    "priority_order = ['High Priority', 'Medium Priority', 'Low Priority', 'Unscored']\n",
    "priority_counts = pipeline_df['priority'].value_counts().reindex(priority_order).fillna(0)\n",
    "colors = ['#27ae60', '#f39c12', '#e74c3c', '#95a5a6']\n",
    "axes[0].bar(priority_order, priority_counts, color=colors)\n",
    "axes[0].set_ylabel('Number of Opportunities')\n",
    "axes[0].set_title('Pipeline by Priority Tier', fontsize=14, fontweight='bold')\n",
    "axes[0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Lead score distribution\n",
    "scored_pipeline = pipeline_df[pipeline_df['lead_score'].notna()]\n",
    "axes[1].hist(scored_pipeline['lead_score'], bins=20, color='#3498db', edgecolor='white')\n",
    "axes[1].axvline(x=70, color='#27ae60', linestyle='--', label='High Priority (70+)')\n",
    "axes[1].axvline(x=50, color='#f39c12', linestyle='--', label='Medium Priority (50+)')\n",
    "axes[1].set_xlabel('Lead Score')\n",
    "axes[1].set_ylabel('Frequency')\n",
    "axes[1].set_title('Lead Score Distribution', fontsize=14, fontweight='bold')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../visuals/09_pipeline_priority.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Save Prioritized Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the scored pipeline\n",
    "output_cols = [\n",
    "    'opportunity_id', 'account', 'product', 'deal_stage', 'sales_agent',\n",
    "    'sector', 'company_size', 'revenue_tier', 'regional_office',\n",
    "    'lead_score', 'priority'\n",
    "]\n",
    "\n",
    "pipeline_output = pipeline_df[output_cols].sort_values('lead_score', ascending=False)\n",
    "pipeline_output.to_csv('../data/prioritized_pipeline.csv', index=False)\n",
    "\n",
    "print(\"Prioritized pipeline saved to: data/prioritized_pipeline.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Model Insights & Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"LEAD PRIORITIZATION MODEL - INSIGHTS & RECOMMENDATIONS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\n1. MODEL PERFORMANCE\")\n",
    "print(f\"   - ROC-AUC Score: {roc_auc_score(y_test, y_prob):.3f}\")\n",
    "print(f\"   - The model can distinguish between likely wins and losses\")\n",
    "\n",
    "print(\"\\n2. KEY PREDICTIVE FACTORS (in order of importance)\")\n",
    "for _, row in feature_importance.iterrows():\n",
    "    print(f\"   - {row['feature']}: {row['importance']*100:.1f}%\")\n",
    "\n",
    "print(\"\\n3. PIPELINE SUMMARY\")\n",
    "for priority in priority_order:\n",
    "    count = (pipeline_df['priority'] == priority).sum()\n",
    "    pct = count / len(pipeline_df) * 100\n",
    "    print(f\"   - {priority}: {count:,} opportunities ({pct:.1f}%)\")\n",
    "\n",
    "high_priority_count = (pipeline_df['priority'] == 'High Priority').sum()\n",
    "print(f\"\\n4. RECOMMENDATIONS\")\n",
    "print(f\"   - Focus sales efforts on {high_priority_count:,} high-priority opportunities\")\n",
    "print(f\"   - {feature_importance.iloc[0]['feature'].title()} is the strongest predictor - segment accordingly\")\n",
    "print(f\"   - Consider additional nurturing for medium-priority leads\")\n",
    "print(f\"   - Review low-priority leads for qualification issues\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
